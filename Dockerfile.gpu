# GPU-enabled training using the official PyTorch CUDA runtime
FROM pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime

WORKDIR /app

# Copy requirements and install
COPY requirements-gpu.txt requirements-base.txt ./
RUN pip install --no-cache-dir -r requirements-gpu.txt

# Copy code
COPY . .

# Default envs
ENV PYTHONUNBUFFERED=1 \
    TOKENIZERS_PARALLELISM=false

# Pre-download HF model/tokenizer (optional; speeds up first run)
RUN python - <<'PY'\
from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\
m='distilbert-base-uncased'\n\
AutoTokenizer.from_pretrained(m, use_fast=True)\n\
AutoModelForSequenceClassification.from_pretrained(m)\n\
print('Cached:', m)\n\
PY

# Entrypoint: single best run from Project 1 (can be overridden with CLI flags)
CMD ["python","main.py","--checkpoint_dir","models","--epochs","3","--seed","42","--train_batch_size","32","--eval_batch_size","64","--optimizer_name","adamw","--lr","1e-4","--lr_scheduler_type","linear","--warmup_ratio","0.11","--weight_decay","0.015"]
